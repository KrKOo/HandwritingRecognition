{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8379f-3008-478f-be11-8c3a767aae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataloader as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from data_augmenter import enrich_and_shuffle_dataset\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, ReLU, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6541bb2-9050-46f3-8952-e403adcda08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_gpu():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Memory growth set successfully\")\n",
    "        except RuntimeError as e:\n",
    "            print(\"Failed to set memory growth: \", e)\n",
    "\n",
    "configure_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451a492-f6e5-4c0e-8489-0e5f87c39b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "LMDB_PATH_HOST=\"..\\dataset\\lmdb.hwr_40-1.0\"\n",
    "TRN_DATA=\"..\\dataset\\data\\lines.filtered_max_width.tst.55.shuf\"\n",
    "TST_DATA=\"..\\dataset\\datalines.filtered_max_width.tst.55\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605ad50-694f-41a8-be99-581d140efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "    imagePairs = []\n",
    "    labelPairs = []\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    numclasses = len(unique_labels)\n",
    "    idx = {label: np.where(labels == label)[0] for label in unique_labels}\n",
    "\n",
    "    for ind in range(len(images)):\n",
    "        currImage = images[ind]\n",
    "        label = labels[ind]\n",
    "\n",
    "        # Choose a positive pair from the same class\n",
    "        if len(idx[label]) > 1:  # Check if there is more than one image in the class\n",
    "            indB = np.random.choice([i for i in idx[label] if i != ind])\n",
    "            indImage = images[indB]\n",
    "            imagePairs.append([currImage, indImage])\n",
    "            labelPairs.append([1])\n",
    "        else:\n",
    "            # Skip if no other images are in the same class\n",
    "            continue\n",
    "\n",
    "        # Choose a negative pair from different class\n",
    "        different_classes = [l for l in unique_labels if l != label]\n",
    "        if different_classes:\n",
    "            diss_label = np.random.choice(different_classes)\n",
    "            diss_idx = np.random.choice(idx[diss_label])\n",
    "            diss_image = images[diss_idx]\n",
    "            imagePairs.append([currImage, diss_image])\n",
    "            labelPairs.append([0])\n",
    "\n",
    "    return (np.array(imagePairs), np.array(labelPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6b77b-9e28-4804-b7a7-c08188951623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dset.DatasetFromLMDB(lmdb_path=LMDB_PATH_HOST, labels_path=TRN_DATA)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for index in range(len(train_set)):\n",
    "    image, label, image_name = train_set[index]\n",
    "    X.append(image)\n",
    "    y.append(label.item())\n",
    "\n",
    "X_tensor = torch.stack(X)\n",
    "X = X_tensor.numpy()\n",
    "X = np.transpose(X, (0, 2, 3, 1))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8356f6-a035-49d6-8ba1-beaf9a1dbb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train, y_train = enrich_and_shuffle_dataset(X_train, y_train)\n",
    "\n",
    "(X_train, y_train) = create_pairs(X_train, y_train)\n",
    "(X_test, y_test) = create_pairs(X_test, y_test)\n",
    "(X_val, y_val) = create_pairs(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd6b82-9e2e-461f-80cf-d7603a876730",
   "metadata": {},
   "source": [
    "# Creating and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc77bd8-0b56-4ac6-8ba0-f934ea5e3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(vecs):\n",
    "    (imgA, imgB) = vecs\n",
    "    imgA_normalized = imgA / K.sqrt(K.maximum(K.sum(K.square(imgA), axis=1, keepdims=True), K.epsilon()))\n",
    "    imgB_normalized = imgB / K.sqrt(K.maximum(K.sum(K.square(imgB), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "    dot_product = K.sum(imgA_normalized * imgB_normalized, axis=1, keepdims=True)\n",
    "\n",
    "    cosine_similarity = dot_product\n",
    "    cosine_distance = 1 - cosine_similarity\n",
    "\n",
    "    return cosine_distance\n",
    "\n",
    "def contrastiveLoss(y, y_preds, margin=1):\n",
    "    y = tf.cast(y, y_preds.dtype)\n",
    "    y_preds_squared = K.square(y_preds)\n",
    "    margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
    "    loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
    "    return loss\n",
    "    \n",
    "def siamese_model(input_shape, embeddingDim=48):\n",
    "    vgg16_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "    for layer in vgg16_base.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    for layer in vgg16_base.layers[-4:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    x = vgg16_base(inputs)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(embeddingDim, activation='relu')(x) \n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9c96d-26dc-4876-93df-9e18cd5f4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (200, 50, 3)\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "imageA = Input(shape = image_shape) \n",
    "imageB = Input(shape = image_shape)\n",
    "\n",
    "model_build = siamese_model(image_shape)\n",
    "modelA = model_build(imageA)\n",
    "modelB = model_build(imageB)\n",
    "\n",
    "distance = Lambda(cosine_distance)([modelA, modelB])\n",
    "model = Model(inputs=[imageA, imageB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d234a03-f738-42ba-8876-a25191ebd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss = contrastiveLoss, optimizer=\"adam\")\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]], y_train[:],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404ba3e-d79d-4998-bacd-9ad438044e2c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ef922-3d88-468a-8842-3cabe6b33f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "batch_size = 32\n",
    "predictions = model.predict([X_test[:, 0], X_test[:, 1]], batch_size=batch_size)\n",
    "\n",
    "similarity_scores = np.exp(-np.array(predictions))\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, similarity_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039298b7-1bc6-4fd7-a152-91cd03e891a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
