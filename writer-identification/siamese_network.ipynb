{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8379f-3008-478f-be11-8c3a767aae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataloader as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451a492-f6e5-4c0e-8489-0e5f87c39b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "LMDB_PATH_HOST=\"..\\dataset\\lmdb.hwr_40-1.0\"\n",
    "TRN_DATA=\"..\\dataset\\data\\lines.filtered_max_width.tst.55.shuf\"\n",
    "TST_DATA=\"..\\dataset\\datalines.filtered_max_width.tst.55\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605ad50-694f-41a8-be99-581d140efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "  imagePairs = []\n",
    "  labelPairs = []\n",
    "\n",
    "  numclasses = len(np.unique(labels))\n",
    "  idx = [np.where(labels ==i)[0] for i in range(numclasses)]\n",
    "\n",
    "  for ind in range(len(images)):\n",
    "    currImage = images[ind]\n",
    "    label = labels[ind]\n",
    "\n",
    "    indB = np.random.choice(idx[label])\n",
    "    indImage = images[indB]\n",
    "\n",
    "    imagePairs.append([currImage, indImage])\n",
    "\n",
    "    labelPairs.append([1])\n",
    "\n",
    "    diss_idx = np.where(labels != label)[0]\n",
    "\n",
    "    diss_image = images[np.random.choice(diss_idx)]\n",
    "\n",
    "    imagePairs.append([currImage, diss_image])\n",
    "    labelPairs.append([0])\n",
    "\n",
    "  return (np.array(imagePairs), np.array(labelPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6b77b-9e28-4804-b7a7-c08188951623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dset.DatasetFromLMDB(lmdb_path=LMDB_PATH_HOST, labels_path=TRN_DATA)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for index in range(len(train_set)):\n",
    "    image, label, image_name = train_set[index]\n",
    "    X_train.append(image)\n",
    "    y_train.append(label.item())\n",
    "\n",
    "X_tensor = torch.stack(X_train)\n",
    "X_train = X_tensor.numpy()\n",
    "y_train = np.array(y_train)\n",
    "(training_pairs, training_labels) = create_pairs(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03061446-bc71-483b-818b-7c2c79c896bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_pairs, test_pairs, train_labels, test_labels = train_test_split(training_pairs, training_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "training_pairs = np.transpose(training_pairs, (0, 1, 3, 4, 2))\n",
    "test_pairs = np.transpose(test_pairs, (0, 1, 3, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07cb2e7-dcf0-4614-86aa-62c5aef5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vecs):\n",
    "  (imgA, imgB) = vecs\n",
    "  ss = K.sum(K.square(imgA - imgB), axis = 1, keepdims=True)\n",
    "  return K.sqrt(K.maximum(ss, K.epsilon()))\n",
    "\n",
    "def contrastiveLoss(y, y_preds, margin=1):\n",
    "    y = tf.cast(y, y_preds.dtype)\n",
    "    y_preds_squared = K.square(y_preds)\n",
    "    margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
    "    loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
    "    return loss\n",
    "    \n",
    "def siamese_model(input_shape, embeddingDim=48, use_pretrained=True):\n",
    "    inputs = Input(input_shape)\n",
    "    if use_pretrained:\n",
    "        base_model = VGG16(include_top=False, input_shape=(input_shape[0], input_shape[1], 3))\n",
    "        x = base_model(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Prvá konvolučná vrstva s pozornosťou\n",
    "    conv1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    attention1 = Conv2D(64, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    x = Multiply()([conv1, attention1])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)  # pridané padding='same'\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Druhá konvolučná vrstva s pozornosťou\n",
    "    conv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    attention2 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    x = Multiply()([conv2, attention2])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)  # pridané padding='same'\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Tretia konvolučná vrstva a GAP\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Fully connected layer pre embedding\n",
    "    outputs = Dense(embeddingDim)(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ba741-2412-46f4-9f08-26cca71a5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (200, 50, 3)\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "imageA = Input(shape = image_shape)\n",
    "imageB = Input(shape = image_shape)\n",
    "\n",
    "model_build = siamese_model(image_shape)\n",
    "modelA = model_build(imageA)\n",
    "modelB = model_build(imageB)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([modelA, modelB])\n",
    "model = Model(inputs=[imageA, imageB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220f1f4-5165-4b85-8a4b-4125a7557219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss = contrastiveLoss, optimizer=\"adam\")\n",
    "\n",
    "history = model.fit(\n",
    "    [training_pairs[:, 0], training_pairs[:, 1]], training_labels[:],\n",
    "    validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7487f-b47c-4ff8-a489-da6311990bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
