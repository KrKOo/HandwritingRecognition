{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8379f-3008-478f-be11-8c3a767aae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dataloader as dset\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from data_augmenter import enrich_and_shuffle_dataset\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, ReLU, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6541bb2-9050-46f3-8952-e403adcda08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_gpu():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Memory growth set successfully\")\n",
    "        except RuntimeError as e:\n",
    "            print(\"Failed to set memory growth: \", e)\n",
    "\n",
    "configure_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451a492-f6e5-4c0e-8489-0e5f87c39b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "LMDB_PATH_HOST=\"..\\dataset\\lmdb.hwr_40-1.0\"\n",
    "TRN_DATA=\"..\\dataset\\data\\lines.filtered_max_width.tst.55.shuf\"\n",
    "TST_DATA=\"..\\dataset\\datalines.filtered_max_width.tst.55\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605ad50-694f-41a8-be99-581d140efe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "    imagePairs = []\n",
    "    labelPairs = []\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    numclasses = len(unique_labels)\n",
    "    idx = {label: np.where(labels == label)[0] for label in unique_labels}\n",
    "\n",
    "    for ind in range(len(images)):\n",
    "        currImage = images[ind]\n",
    "        label = labels[ind]\n",
    "\n",
    "        # Choose a positive pair from the same class\n",
    "        if len(idx[label]) > 1:  # Check if there is more than one image in the class\n",
    "            indB = np.random.choice([i for i in idx[label] if i != ind])\n",
    "            indImage = images[indB]\n",
    "            imagePairs.append([currImage, indImage])\n",
    "            labelPairs.append([1])\n",
    "        else:\n",
    "            # Skip if no other images are in the same class\n",
    "            continue\n",
    "\n",
    "        # Choose a negative pair from different class\n",
    "        different_classes = [l for l in unique_labels if l != label]\n",
    "        if different_classes:\n",
    "            diss_label = np.random.choice(different_classes)\n",
    "            diss_idx = np.random.choice(idx[diss_label])\n",
    "            diss_image = images[diss_idx]\n",
    "            imagePairs.append([currImage, diss_image])\n",
    "            labelPairs.append([0])\n",
    "\n",
    "    return (np.array(imagePairs), np.array(labelPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6b77b-9e28-4804-b7a7-c08188951623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dset.DatasetFromLMDB(lmdb_path=LMDB_PATH_HOST, labels_path=TRN_DATA)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for index in range(len(train_set)):\n",
    "    image, label, image_name = train_set[index]\n",
    "    X.append(image)\n",
    "    y.append(label.item())\n",
    "\n",
    "X_tensor = torch.stack(X)\n",
    "X = X_tensor.numpy()\n",
    "X = np.transpose(X, (0, 2, 3, 1))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1ce2f-585c-4d71-b9a3-c3c022301ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1624446-b0e7-4ec6-9b95-ef462028380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8356f6-a035-49d6-8ba1-beaf9a1dbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train, y_train = enrich_and_shuffle_dataset(X_train, y_train)\n",
    "\n",
    "(X_train, y_train) = create_pairs(X_train, y_train)\n",
    "(X_test, y_test) = create_pairs(X_test, y_test)\n",
    "(X_val, y_val) = create_pairs(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd6b82-9e2e-461f-80cf-d7603a876730",
   "metadata": {},
   "source": [
    "# Creating and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728bfba1-e9eb-4f8a-9105-8ef6fcb8e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    vector1, vector2 = vectors\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(vector1 - vector2), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, y_pred.dtype) \n",
    "    margin = 1.0\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    \n",
    "image_shape = (200, 50, 3)\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "# Load VGG16 without the fully connected layers at the top and with ImageNet weights\n",
    "vgg16_base = VGG16(include_top=False, weights='imagenet', input_shape=(200, 50, 3))\n",
    "\n",
    "# Decide which layers to freeze during training (optional, for fine-tuning)\n",
    "for layer in vgg16_base.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "# Adding custom layers on top of VGG16 to create embeddings\n",
    "inputs = Input(shape=(200, 50, 3))\n",
    "x = vgg16_base(inputs)\n",
    "x = GlobalAveragePooling2D()(x)  # This converts the MxNxC tensor output into a 1xC tensor\n",
    "x = Dense(512, activation='relu')(x)  # Example of a custom dense layer for embeddings\n",
    "embeddings = Dense(128, activation='relu')(x)  # Output layer for embeddings\n",
    "embedding_model = Model(inputs, embeddings)\n",
    "\n",
    "# Define two inputs for the Siamese network\n",
    "input_a = Input(shape=image_shape)\n",
    "input_b = Input(shape=image_shape)\n",
    "\n",
    "# Generate embeddings for both inputs\n",
    "embedding_a = embedding_model(input_a)\n",
    "embedding_b = embedding_model(input_b)\n",
    "\n",
    "# Calculate the Euclidean distance between the embeddings\n",
    "distance = Lambda(euclidean_distance)([embedding_a, embedding_b])\n",
    "\n",
    "# Siamese Network Model\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=contrastive_loss)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]], y_train[:],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d326378-be30-47d2-8e32-fd39aa1b35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, Lambda, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "image_shape = (200, 50, 3)\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    vector1, vector2 = vectors\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(vector1 - vector2), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    margin = 1.0\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "# Load ResNet50 without the fully connected layers at the top and with ImageNet weights\n",
    "resnet_base = ResNet50(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "\n",
    "# Freeze layers for fine-tuning (optional)\n",
    "for layer in resnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom layers on top of ResNet to create embeddings\n",
    "inputs = Input(shape=image_shape)\n",
    "x = resnet_base(inputs)\n",
    "x = GlobalAveragePooling2D()(x)  # Converts the MxNxC tensor output into a 1xC tensor\n",
    "x = Dense(512, activation='relu')(x)  # Example of a custom dense layer for embeddings\n",
    "embeddings = Dense(128, activation='relu')(x)  # Output layer for embeddings\n",
    "embedding_model = Model(inputs, embeddings)\n",
    "\n",
    "# Define two inputs for the Siamese network\n",
    "input_a = Input(shape=image_shape)\n",
    "input_b = Input(shape=image_shape)\n",
    "\n",
    "# Generate embeddings for both inputs\n",
    "embedding_a = embedding_model(input_a)\n",
    "embedding_b = embedding_model(input_b)\n",
    "\n",
    "# Calculate the Euclidean distance between the embeddings\n",
    "distance = Lambda(euclidean_distance)([embedding_a, embedding_b])\n",
    "\n",
    "# Siamese Network Model\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=contrastive_loss)\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]], y_train[:],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404ba3e-d79d-4998-bacd-9ad438044e2c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ef922-3d88-468a-8842-3cabe6b33f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "batch_size = 32  # You can adjust this based on your system's capabilities\n",
    "predictions = model.predict([X_test[:, 0], X_test[:, 1]], batch_size=batch_size)\n",
    "\n",
    "similarity_scores = np.exp(-np.array(predictions))\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, similarity_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da40ff6-e762-4e6e-a616-f4bb4ee4d25a",
   "metadata": {},
   "source": [
    "# My Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c2bef-d44b-41f2-a449-7c636372bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vecs):\n",
    "    (imgA, imgB) = vecs\n",
    "    # Normalize each vector to unit length\n",
    "    imgA_normalized = imgA / K.sqrt(K.maximum(K.sum(K.square(imgA), axis=1, keepdims=True), K.epsilon()))\n",
    "    imgB_normalized = imgB / K.sqrt(K.maximum(K.sum(K.square(imgB), axis=1, keepdims=True), K.epsilon()))\n",
    "    \n",
    "    # Calculate the squared Euclidean distance between the normalized vectors\n",
    "    squared_differences = K.square(imgA_normalized - imgB_normalized)\n",
    "    sum_squared_differences = K.sum(squared_differences, axis=1, keepdims=True)\n",
    "    \n",
    "    # Return the square root of the sum of squared differences\n",
    "    return K.sqrt(K.maximum(sum_squared_differences, K.epsilon()))\n",
    "\n",
    "def contrastiveLoss(y, y_preds, margin=1):\n",
    "    y = tf.cast(y, y_preds.dtype)\n",
    "    y_preds_squared = K.square(y_preds)\n",
    "    margin_squared = K.square(K.maximum(margin - y_preds, 0))\n",
    "    loss = K.mean(y * y_preds_squared + (1 - y) * margin_squared)\n",
    "    return loss\n",
    "    \n",
    "def siamese_model(input_shape, embeddingDim=48):\n",
    "    x = Input(input_shape)\n",
    "    \n",
    "    # Prvá konvolučná vrstva s pozornosťou\n",
    "    conv1 = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(conv1)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Druhá konvolučná vrstva s pozornosťou\n",
    "    conv2 = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(conv2)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)  \n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Tretia konvolučná vrstva a GAP\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Fully connected layer pre embedding\n",
    "    outputs = Dense(embeddingDim)(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220f1f4-5165-4b85-8a4b-4125a7557219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss = contrastiveLoss, optimizer=\"adam\")\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]], y_train[:],\n",
    "    validation_data=([X_val[:, 0], X_val[:, 1]], y_val[:]),\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ba741-2412-46f4-9f08-26cca71a5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (200, 50, 3)\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "imageA = Input(shape = image_shape) \n",
    "imageB = Input(shape = image_shape)\n",
    "\n",
    "model_build = siamese_model(image_shape)\n",
    "modelA = model_build(imageA)\n",
    "modelB = model_build(imageB)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([modelA, modelB])\n",
    "model = Model(inputs=[imageA, imageB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89ad06-e0fd-48ca-9aad-8080ab2749f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
